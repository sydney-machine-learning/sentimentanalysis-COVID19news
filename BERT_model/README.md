# BERT model part: 
This part is the BERT model. Among them, BERT_model.ipynb contains the preprocessing and model adjustment of the BERT model. 
Since the overall labelled data is relatively large, we divided it into sections according to the section name: 
Australia news, UK news, World news and Opinion. 
And a link to the Glovefile file we used in the model preprocessing step.
# GloVe
This link is "glove.840B.300d.txt" and is a text file containing pre-trained word embeddings 
generated using the GloVe algorithm and trained on a large corpus of text data. 
Each word in the vocabulary is represented as a dense vector of 300 dimensions.
Download from: https://github.com/stanfordnlp/GloVe
