{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb","timestamp":1710076783937}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"fdd67366256a4d27a2eb183d2cbf290b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6271ff782f354f7facaa0f5110f5423e","IPY_MODEL_adf7af91d89c4446bbc75e194e755d48","IPY_MODEL_7053f82de5d14571a4f12731f52ea95b"],"layout":"IPY_MODEL_fc98cf2a16af4e8c9909602bb890a8be"}},"6271ff782f354f7facaa0f5110f5423e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d02f338efb0415d91c547e6d6be9e35","placeholder":"​","style":"IPY_MODEL_25759588b0ea4b43b01b1c645725441c","value":"Map: 100%"}},"adf7af91d89c4446bbc75e194e755d48":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_60310a22c0d048c68687ae816946250a","max":8000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a705851633848d6a353091da792941b","value":8000}},"7053f82de5d14571a4f12731f52ea95b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f66e02cfc7d4774a6a00c705c1bf1fb","placeholder":"​","style":"IPY_MODEL_231ad89fcc5f4c839833dc813406d394","value":" 8000/8000 [00:03&lt;00:00, 2556.78 examples/s]"}},"fc98cf2a16af4e8c9909602bb890a8be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d02f338efb0415d91c547e6d6be9e35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25759588b0ea4b43b01b1c645725441c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"60310a22c0d048c68687ae816946250a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a705851633848d6a353091da792941b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f66e02cfc7d4774a6a00c705c1bf1fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"231ad89fcc5f4c839833dc813406d394":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b974ea5efb4b41ebb71467987d5bf24f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_109e947baef7453c93f9695024f36ba2","IPY_MODEL_ffb899f0a6a5417ebe7f6923ee0d7a6e","IPY_MODEL_dbd826de0b9b488a8589111bd92598ff"],"layout":"IPY_MODEL_eedcf253c7e648718cf3d0787734e7b1"}},"109e947baef7453c93f9695024f36ba2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a5ec4705dfd4cfea86411acff4d7f82","placeholder":"​","style":"IPY_MODEL_1ed62a6c5fdb42c5a5612bc290e9e6e7","value":"Map: 100%"}},"ffb899f0a6a5417ebe7f6923ee0d7a6e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a633d1947cb44c289fcd9d030b9d7a2","max":2000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff3843ee59de4ef0a44aa6ba814d1cad","value":2000}},"dbd826de0b9b488a8589111bd92598ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1444173d5e8c4ccc89ca4cbbb7426db6","placeholder":"​","style":"IPY_MODEL_c1846bf8b32648d2b9b666dc00e27d91","value":" 2000/2000 [00:00&lt;00:00, 2867.15 examples/s]"}},"eedcf253c7e648718cf3d0787734e7b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a5ec4705dfd4cfea86411acff4d7f82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ed62a6c5fdb42c5a5612bc290e9e6e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a633d1947cb44c289fcd9d030b9d7a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff3843ee59de4ef0a44aa6ba814d1cad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1444173d5e8c4ccc89ca4cbbb7426db6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1846bf8b32648d2b9b666dc00e27d91":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","metadata":{"id":"4wxY3x-ZZz8h","executionInfo":{"status":"ok","timestamp":1710165525261,"user_tz":-660,"elapsed":7017,"user":{"displayName":"yiruo ma","userId":"14693054244955981335"}},"outputId":"7b75085e-2a0f-4a64-e26f-8d889f85902e","colab":{"base_uri":"https://localhost:8080/"}},"source":["#Set up the environment\n","!pip install -q transformers datasets"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["#Download the accelarator\n","!pip install transformers[torch] -U"],"metadata":{"id":"ywW5MSZKFZXQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710165535337,"user_tz":-660,"elapsed":6756,"user":{"displayName":"yiruo ma","userId":"14693054244955981335"}},"outputId":"37d01874-6a8a-4d13-c484-f69a8c8418e2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n","Collecting accelerate>=0.21.0 (from transformers[torch])\n","  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.27.2\n"]}]},{"cell_type":"code","source":["#Import the library\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from datasets import Dataset, DatasetDict"],"metadata":{"id":"sMBM7p3u3hPd"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sd1LiXGjZ420","outputId":"80bc44c3-1ea1-430c-afc4-49271a3c5079","executionInfo":{"status":"ok","timestamp":1710132910395,"user_tz":-480,"elapsed":20263,"user":{"displayName":"Jieyi Tang","userId":"04005180581446136122"}}},"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Import pandas\n","import pandas as pd\n","\n","# Read the CSV file into a DataFrame\n","file_path = '/content/drive/My Drive/Sentiment Analysis/data.csv'\n","df = pd.read_csv(file_path)"],"metadata":{"id":"SnbQGxRDoqyW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the shape of data\n","df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pPcWAQE8BTRI","executionInfo":{"status":"ok","timestamp":1710136009635,"user_tz":-480,"elapsed":3,"user":{"displayName":"Jieyi Tang","userId":"04005180581446136122"}},"outputId":"2b367881-45b7-49e0-d728-fcc7db1eb357"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 14)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# Split the dataset into training and validation sets\n","train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","# Create Dataset objects\n","train_dataset = Dataset.from_pandas(train_df)\n","val_dataset = Dataset.from_pandas(val_df)\n","\n","# Create DatasetDict object\n","dataset = DatasetDict({\n","    'train': train_dataset,\n","    'validation': val_dataset\n","})\n","\n","dataset = dataset.remove_columns(\"__index_level_0__\")\n","dataset = dataset.remove_columns(\"Unnamed: 0\")\n","# Display the dataset\n","dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"grusaAPMseiY","executionInfo":{"status":"ok","timestamp":1710136047839,"user_tz":-480,"elapsed":252,"user":{"displayName":"Jieyi Tang","userId":"04005180581446136122"}},"outputId":"d35efba4-4015-4c58-fa6b-6242ddf5e4d1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['ID', 'Tweet', 'Optimistic', 'Thankful', 'Empathetic', 'Pessimistic', 'Anxious', 'Sad', 'Annoyed', 'Denial', 'Official report', 'Surprise', 'Joking'],\n","        num_rows: 8000\n","    })\n","    validation: Dataset({\n","        features: ['ID', 'Tweet', 'Optimistic', 'Thankful', 'Empathetic', 'Pessimistic', 'Anxious', 'Sad', 'Annoyed', 'Denial', 'Official report', 'Surprise', 'Joking'],\n","        num_rows: 2000\n","    })\n","})"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"unjuTtKUjZI3","outputId":"c77430d8-4f58-4e26-a01d-7ab23d824e28","executionInfo":{"status":"ok","timestamp":1710136052669,"user_tz":-480,"elapsed":271,"user":{"displayName":"Jieyi Tang","userId":"04005180581446136122"}}},"source":["# Check the sample data\n","example = dataset['train'][0]\n","example"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'ID': 1245204293461966849,\n"," 'Tweet': 'This quarantine got me watching everyone’s snap story without skipping any 😂😭 #COVID19 #QuaratineLife #StayAtHomePlease #StayAtHome',\n"," 'Optimistic': 1,\n"," 'Thankful': 0,\n"," 'Empathetic': 0,\n"," 'Pessimistic': 0,\n"," 'Anxious': 0,\n"," 'Sad': 1,\n"," 'Annoyed': 0,\n"," 'Denial': 0,\n"," 'Official report': 0,\n"," 'Surprise': 0,\n"," 'Joking': 0}"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e5vZhQpvkE8s","outputId":"a40a78b7-dab1-4284-ecb4-be3acc642c97","executionInfo":{"status":"ok","timestamp":1710136057280,"user_tz":-480,"elapsed":259,"user":{"displayName":"Jieyi Tang","userId":"04005180581446136122"}}},"source":["#It create a mapping relationship betweeen label and its index\n","labels = [label for label in dataset['train'].features.keys() if label not in ['ID', 'Tweet']]\n","id2label = {idx:label for idx, label in enumerate(labels)}\n","label2id = {label:idx for idx, label in enumerate(labels)}\n","labels"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Optimistic',\n"," 'Thankful',\n"," 'Empathetic',\n"," 'Pessimistic',\n"," 'Anxious',\n"," 'Sad',\n"," 'Annoyed',\n"," 'Denial',\n"," 'Official report',\n"," 'Surprise',\n"," 'Joking']"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"AFWlSsbZaRLc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710136070750,"user_tz":-480,"elapsed":10845,"user":{"displayName":"Jieyi Tang","userId":"04005180581446136122"}},"outputId":"2361960a-ed27-4fba-c071-78757c3fb0f2"},"source":["#Use the AutoTokenizer API to tokenize the data, define the function to process the data including making sure all the data having the same length\n","#create a array to store the key number for each lable\n","from transformers import AutoTokenizer\n","import numpy as np\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","def preprocess_data(examples):\n","  # take a batch of texts\n","  text = examples[\"Tweet\"]\n","  # encode them\n","  encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n","  # add labels\n","  labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n","  # create numpy array of shape (batch_size, num_labels)\n","  labels_matrix = np.zeros((len(text), len(labels)))\n","  # fill numpy array\n","  for idx, label in enumerate(labels):\n","    labels_matrix[:, idx] = labels_batch[label]\n","\n","  encoding[\"labels\"] = labels_matrix.tolist()\n","\n","  return encoding"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","metadata":{"id":"i4ENBTdulBEI","colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["fdd67366256a4d27a2eb183d2cbf290b","6271ff782f354f7facaa0f5110f5423e","adf7af91d89c4446bbc75e194e755d48","7053f82de5d14571a4f12731f52ea95b","fc98cf2a16af4e8c9909602bb890a8be","9d02f338efb0415d91c547e6d6be9e35","25759588b0ea4b43b01b1c645725441c","60310a22c0d048c68687ae816946250a","2a705851633848d6a353091da792941b","2f66e02cfc7d4774a6a00c705c1bf1fb","231ad89fcc5f4c839833dc813406d394","b974ea5efb4b41ebb71467987d5bf24f","109e947baef7453c93f9695024f36ba2","ffb899f0a6a5417ebe7f6923ee0d7a6e","dbd826de0b9b488a8589111bd92598ff","eedcf253c7e648718cf3d0787734e7b1","8a5ec4705dfd4cfea86411acff4d7f82","1ed62a6c5fdb42c5a5612bc290e9e6e7","8a633d1947cb44c289fcd9d030b9d7a2","ff3843ee59de4ef0a44aa6ba814d1cad","1444173d5e8c4ccc89ca4cbbb7426db6","c1846bf8b32648d2b9b666dc00e27d91"]},"executionInfo":{"status":"ok","timestamp":1710136078326,"user_tz":-480,"elapsed":4800,"user":{"displayName":"Jieyi Tang","userId":"04005180581446136122"}},"outputId":"4a4fe4d4-1261-4800-f7d5-883e404989b9"},"source":["#Process all the data with the given function\n","encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdd67366256a4d27a2eb183d2cbf290b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b974ea5efb4b41ebb71467987d5bf24f"}},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0enAb0W9o25W","outputId":"8659f32e-7325-44f6-af94-6661ec513eac","executionInfo":{"status":"ok","timestamp":1710136080076,"user_tz":-480,"elapsed":440,"user":{"displayName":"Jieyi Tang","userId":"04005180581446136122"}}},"source":["#Check the features\n","example = encoded_dataset['train'][0]\n","print(example.keys())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"D0McCtJ8HRJY","outputId":"bd44be82-7709-4548-ee1b-1743652dea0a","executionInfo":{"status":"ok","timestamp":1710136085042,"user_tz":-480,"elapsed":4063,"user":{"displayName":"Jieyi Tang","userId":"04005180581446136122"}}},"source":["#Check the example\n","tokenizer.decode(example['input_ids'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'[CLS] this quarantine got me watching everyone ’ s snap story without skipping any [UNK] # covid19 # quaratinelife # stayathomeplease # stayathome [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VdIvj6WjHeZQ","outputId":"cd823509-9fd6-496e-d23a-a765f9a1d089","executionInfo":{"status":"ok","timestamp":1710136086367,"user_tz":-480,"elapsed":256,"user":{"displayName":"Jieyi Tang","userId":"04005180581446136122"}}},"source":["#Check the example's labels\n","example['labels']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q4Dx95t2o6N9","outputId":"3165b589-af31-45db-bc8c-b688ff0d9aec","executionInfo":{"status":"ok","timestamp":1710136087770,"user_tz":-480,"elapsed":253,"user":{"displayName":"Jieyi Tang","userId":"04005180581446136122"}}},"source":["#Return the label\n","[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Optimistic', 'Sad']"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"Lk6Cq9duKBkA"},"source":["#We set the format of out data into standard PyTorch datasets\n","encoded_dataset.set_format(\"torch\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6XPL1Z_RegBF","outputId":"a478b559-45ea-458f-8a93-1cc42a84536f","executionInfo":{"status":"ok","timestamp":1710136095556,"user_tz":-480,"elapsed":5012,"user":{"displayName":"Jieyi Tang","userId":"04005180581446136122"}}},"source":["#Load the model for training\n","from transformers import AutoModelForSequenceClassification\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n","                                                           problem_type=\"multi_label_classification\",\n","                                                           num_labels=len(labels),\n","                                                           id2label=id2label,\n","                                                           label2id=label2id)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","metadata":{"id":"K5a8_vIKqr7P"},"source":["#We define the batch size and the metrics to evaluate the model\n","batch_size = 8\n","metric_name = \"f1\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dR2GmpvDqbuZ"},"source":["#Define the training hyperparamerters, for example, we want to evaluate after every epoch of training and save the results every epoch, leaning rate and the batch size\n","# and the number of epochs to train for\n","from transformers import TrainingArguments, Trainer\n","\n","args = TrainingArguments(\n","    f\"bert-finetuned-sem_eval-english\",\n","    evaluation_strategy = \"epoch\",\n","    save_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=5,\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=metric_name,\n","    #push_to_hub=True,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"797b2WHJqUgZ"},"source":["#Define the function to evaluate the results\n","from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n","from transformers import EvalPrediction\n","import torch\n","\n","def multi_label_metrics(predictions, labels, threshold=0.5):\n","    # first, use sigmoid on predictions which are of shape (batch_size, num_labels)\n","    sigmoid = torch.nn.Sigmoid()\n","    probs = sigmoid(torch.Tensor(predictions))\n","    # next, use threshold to turn them into integer predictions\n","    y_pred = np.zeros(probs.shape)\n","    y_pred[np.where(probs >= threshold)] = 1\n","    # finally, compute metrics\n","    y_true = labels\n","    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n","    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n","    accuracy = accuracy_score(y_true, y_pred)\n","    # return as dictionary\n","    metrics = {'f1': f1_micro_average,\n","               'roc_auc': roc_auc,\n","               'accuracy': accuracy}\n","    return metrics\n","\n","def compute_metrics(p: EvalPrediction):\n","    preds = p.predictions[0] if isinstance(p.predictions,\n","            tuple) else p.predictions\n","    result = multi_label_metrics(\n","        predictions=preds,\n","        labels=p.label_ids)\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"IlOgGiojuWwG","outputId":"ba1780b3-308f-4f47-d397-51fd87d264b6","executionInfo":{"status":"ok","timestamp":1710136105233,"user_tz":-480,"elapsed":4,"user":{"displayName":"Jieyi Tang","userId":"04005180581446136122"}}},"source":["#Check the label type\n","encoded_dataset['train'][0]['labels'].type()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'torch.FloatTensor'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y41Kre_jvD7x","outputId":"4d8d451b-925f-4abb-9861-f7f9cf0e3e59","executionInfo":{"status":"ok","timestamp":1710136108006,"user_tz":-480,"elapsed":247,"user":{"displayName":"Jieyi Tang","userId":"04005180581446136122"}}},"source":["#Check the encoding example\n","encoded_dataset['train']['input_ids'][0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([  101,  2023, 24209, 20486, 10196,  2288,  2033,  3666,  3071,  1521,\n","         1055, 10245,  2466,  2302, 25978,  2151,   100,  1001,  2522, 17258,\n","        16147,  1001, 24209, 25879,  3170, 15509,  1001,  2994,  8988,  8462,\n","        10814, 11022,  1001,  2994,  8988,  8462,   102,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sxWcnZ8ku12V","outputId":"3b79a71e-16f3-43e4-d321-49fa059e7993","executionInfo":{"status":"ok","timestamp":1710136111285,"user_tz":-480,"elapsed":1470,"user":{"displayName":"Jieyi Tang","userId":"04005180581446136122"}}},"source":["#Performa a forward pass to model\n","outputs = model(input_ids=encoded_dataset['train']['input_ids'][0].unsqueeze(0), labels=encoded_dataset['train'][0]['labels'].unsqueeze(0))\n","outputs"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"]},{"output_type":"execute_result","data":{"text/plain":["SequenceClassifierOutput(loss=tensor(0.7206, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), logits=tensor([[-0.2891, -0.1942,  0.1110, -0.1462,  0.2849, -0.2215, -0.2619,  0.5243,\n","         -0.1114, -0.4090,  0.0934]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"chq_3nUz73ib"},"source":["#Start to train the model\n","trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=encoded_dataset[\"train\"],\n","    eval_dataset=encoded_dataset[\"validation\"],\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":196},"id":"KXmFds8js6P8","outputId":"79ad8ac1-6e45-4eea-9cb7-f8ce30572164"},"source":["trainer.train()"],"execution_count":null,"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1104' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1104/5000 4:02:42 < 14:18:03, 0.08 it/s, Epoch 1.10/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1</th>\n","      <th>Roc Auc</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.351500</td>\n","      <td>0.335522</td>\n","      <td>0.484526</td>\n","      <td>0.666281</td>\n","      <td>0.200000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1108' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1108/5000 4:03:43 < 14:17:41, 0.08 it/s, Epoch 1.11/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1</th>\n","      <th>Roc Auc</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.351500</td>\n","      <td>0.335522</td>\n","      <td>0.484526</td>\n","      <td>0.666281</td>\n","      <td>0.200000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"cMlebJ83LRYG","outputId":"b18102e7-2198-4beb-c874-d39636f740ed"},"source":["#We evaluate the model\n","trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 886\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='519' max='408' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [408/408 02:01]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 5.0,\n"," 'eval_accuracy': 0.2799097065462754,\n"," 'eval_f1': 0.7096149188665537,\n"," 'eval_loss': 0.31915703415870667,\n"," 'eval_roc_auc': 0.805805895058838,\n"," 'eval_runtime': 4.7187,\n"," 'eval_samples_per_second': 187.766,\n"," 'eval_steps_per_second': 23.524}"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"3fxjfr8PLD42"},"source":["#Test a model on a new sentence\n","text = \"I'm happy I can finally train a model for multi-label classification\"\n","\n","#Tokenize the text\n","encoding = tokenizer(text, return_tensors=\"pt\")\n","\n","#Move the tensor to the device where the model is loaded\n","encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n","\n","#Pass the device-adapted input to the pre-trained model\n","outputs = trainer.model(**encoding)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KOBosj4UL2tU","outputId":"be370f49-3840-4c76-b193-76083e49701e"},"source":["#The logits is a tensor that contains the scores for every individual label.\n","logits = outputs.logits\n","logits.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 11])"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mEkAQleMMT0k","outputId":"fddb51cb-bf01-420a-fd5b-4a7c2e775446"},"source":["# apply a sigmoid function independently to every score, such that every score is turned into a number between 0 and 1,\n","#that can be interpreted as a \"probability\" for how certain the model is that a given class belongs to the input text.\n","sigmoid = torch.nn.Sigmoid()\n","probs = sigmoid(logits.squeeze().cpu())\n","predictions = np.zeros(probs.shape)\n","#we use a threshold (typically, 0.5) to turn every probability into either a 1 or a 0\n","predictions[np.where(probs >= 0.5)] = 1\n","# turn predicted id's into actual label names\n","predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n","print(predicted_labels)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['joy', 'optimism']\n"]}]},{"cell_type":"code","source":["#Define the place to save the trained model\n","output_model_dir = '/content/drive/My Drive/Colab Notebooks/Fine Tuned BERT Model'"],"metadata":{"id":"YNdBy3dpCJGw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Save the model\n","trainer.model.save_pretrained(output_model_dir)"],"metadata":{"id":"h54YxKRYCt39"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the trained BERT model\n","from transformers import BertForSequenceClassification\n","\n","loaded_model = BertForSequenceClassification.from_pretrained(output_model_dir)"],"metadata":{"id":"8ptmFGPpCNkC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Use the trained model to make prediction\n","text = \"I'm happy and thanks!\"\n","\n","encoding = tokenizer(text, return_tensors=\"pt\")\n","encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n","\n","outputs = trainer.model(**encoding)"],"metadata":{"id":"lyLNQmtuCkI_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#The logits is a tensor that contains the scores for every individual label.\n","logits = outputs.logits\n","logits.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"84JEdl_YClVj","executionInfo":{"status":"ok","timestamp":1710085583724,"user_tz":-480,"elapsed":343,"user":{"displayName":"Jieyi Tang","userId":"04005180581446136122"}},"outputId":"f01d57be-221d-4e73-aae1-411a59c5d205"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 10])"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["# apply sigmoid + threshold\n","sigmoid = torch.nn.Sigmoid()\n","probs = sigmoid(logits.squeeze().cpu())\n","predictions = np.zeros(probs.shape)\n","predictions[np.where(probs >= 0.5)] = 1\n","# turn predicted id's into actual label names\n","predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n","print(predicted_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Oe7c6ipCmpf","executionInfo":{"status":"ok","timestamp":1710085585754,"user_tz":-480,"elapsed":2,"user":{"displayName":"Jieyi Tang","userId":"04005180581446136122"}},"outputId":"f93cc3a9-d674-4a32-a619-521e25c67f6c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Optimistic', 'Thankful']\n"]}]}]}